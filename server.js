const express = require('express');
const { OpenAI } = require('openai');
const cors = require('cors');
const { connect } = require('@lancedb/lancedb');
const { OpenAIEmbeddings } = require('@langchain/openai');
const fileUpload = require('express-fileupload');
const pdf = require('pdf-parse'); 
require('dotenv').config();

const app = express();

// --- 1. MIDDLEWARE (CORS MUST BE FIRST) ---
app.use(cors({
ย ย origin: '*', // Allows Netlify to communicate with Render
ย ย methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
ย ย allowedHeaders: ['Content-Type', 'Authorization']
}));
app.options('(.*)', cors()); // Explicitly handle preflight requests

app.use(express.json({ limit: '50mb' })); 
app.use(express.static(__dirname));
app.use(fileUpload());

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const embeddings = new OpenAIEmbeddings();

// --- 2. CLOUD CONFIGURATION ---
const DB_PATH = "s3://be-advocates-legal-data/lancedb";
const SESSION_TABLE = 'session_context';
const STATUTE_TABLE = 'nc_statutes';

const chapterMap = {
ย ย "20": "Motor Vehicles Traffic Speeding Ticket Driving License",
ย ย "42": "Landlord Tenant Rent Eviction Lease Repairs",
ย ย "50": "Divorce Alimony Family Child Support Custody",
ย ย "1A": "Civil Procedure Summons Debt Lawsuit Default",
ย ย "122C": "Mental Health"
};

/**
ย* 3. SESSION MANAGEMENT
ย*/
app.post('/api/train', async (req, res) => {
ย ย try {
ย ย ย ย const { text, sourceName } = req.body;
ย ย ย ย const db = await connect(DB_PATH);
ย ย ย ย const vector = await embeddings.embedQuery(text);
ย ย ย ย let table;
ย ย ย ย try { table = await db.openTable(SESSION_TABLE); } 
ย ย ย ย catch (e) { table = await db.createTable(SESSION_TABLE, [{ vector, text, source: sourceName }]); return res.json({ success: true }); }
ย ย ย ย await table.add([{ vector, text, source: sourceName }]);
ย ย ย ย res.json({ success: true });
ย ย } catch (error) { res.status(500).json({ error: "Training failed." }); }
});

app.post('/api/clear-session', async (req, res) => {
ย ย try {
ย ย ย ย const db = await connect(DB_PATH);
ย ย ย ย await db.dropTable(SESSION_TABLE).catch(() => {}); 
ย ย ย ย res.json({ success: true });
ย ย } catch (e) { res.json({ success: true }); }
});

/**
ย* 4. CORE NAVIGATOR ENGINE (Hybrid Search)
ย*/
app.post('/api/chat', async (req, res) => {
ย ย try {
ย ย ย ย const { message, image, mimeType } = req.body; 
ย ย ย ย let extractedText = "";

ย ย ย ย // Step A: Multi-Format Ingestion
ย ย ย ย if (image) {
ย ย ย ย ย ย if (mimeType === 'text/plain') {
ย ย ย ย ย ย ย ย extractedText = Buffer.from(image, 'base64').toString('utf-8');
ย ย ย ย ย ย } 
ย ย ย ย ย ย else if (mimeType === 'application/pdf') {
ย ย ย ย ย ย ย ย const buffer = Buffer.from(image, 'base64');
ย ย ย ย ย ย ย ย const pdfData = await pdf(buffer);
ย ย ย ย ย ย ย ย extractedText = pdfData.text;
ย ย ย ย ย ย } 
ย ย ย ย ย ย else if (mimeType && mimeType.startsWith('image/')) {
ย ย ย ย ย ย ย ย const visionResponse = await openai.chat.completions.create({
ย ย ย ย ย ย ย ย ย ย model: "gpt-4o-mini",
ย ย ย ย ย ย ย ย ย ย messages: [{
ย ย ย ย ย ย ย ย ย ย ย ย role: "user",
ย ย ย ย ย ย ย ย ย ย ย ย content: [
ย ย ย ย ย ย ย ย ย ย ย ย ย ย { type: "text", text: "Extract legal issue and NCGS statute numbers." },
ย ย ย ย ย ย ย ย ย ย ย ย ย ย { type: "image_url", image_url: { url: `data:${mimeType};base64,${image}` } }
ย ย ย ย ย ย ย ย ย ย ย ย ],
ย ย ย ย ย ย ย ย ย ย }],
ย ย ย ย ย ย ย ย });
ย ย ย ย ย ย ย ย extractedText = visionResponse.choices[0].message.content;
ย ย ย ย ย ย }
ย ย ย ย }

ย ย ย ย // Step B: Build Hybrid Query
ย ย ย ย let hybridQuery = `DOCUMENT CONTENT: ${extractedText} \n\nUSER QUESTION: ${message || "Analyze this."}`;

ย ย ย ย // Step C: Chapter Locking Logic
ย ย ย ย let detectedChapter = "";
ย ย ย ย const scanText = hybridQuery.toLowerCase();
ย ย ย ย for (const [num, keywords] of Object.entries(chapterMap)) {
ย ย ย ย ย ย if (keywords.toLowerCase().split(' ').some(word => scanText.includes(word))) {
ย ย ย ย ย ย ย ย detectedChapter = num;
ย ย ย ย ย ย ย ย break;
ย ย ย ย ย ย }
ย ย ย ย }

ย ย ย ย // Step D: Vector Search on S3
ย ย ย ย const finalSearchString = detectedChapter ? `NCGS Chapter ${detectedChapter} ${hybridQuery}` : hybridQuery;
ย ย ย ย const db = await connect(DB_PATH);
ย ย ย ย const queryVector = await embeddings.embedQuery(finalSearchString);
ย ย ย ย 
ย ย ย ย const statuteTable = await db.openTable(STATUTE_TABLE);
ย ย ย ย const statuteResults = await statuteTable.search(queryVector).limit(15).toArray();

ย ย ย ย let sessionResults = [];
ย ย ย ย try {
ย ย ย ย ย ย const sessionTable = await db.openTable(SESSION_TABLE);
ย ย ย ย ย ย sessionResults = await sessionTable.search(queryVector).limit(3).toArray();
ย ย ย ย } catch (e) {}

ย ย ย ย // Step E: Context Assembly
ย ย ย ย let retrievedContext = detectedChapter ? `*** PRIMARY LEGAL FOCUS: NCGS CHAPTER ${detectedChapter} ***\n` : "";
ย ย ย ย statuteResults.forEach(r => retrievedContext += `[Source: ${r.source}]\n${r.text}\n\n`);
ย ย ย ย 
ย ย ย ย if (sessionResults.length > 0) {
ย ย ย ย ย ย retrievedContext += "--- USER PERSONAL DOCUMENTS ---\n";
ย ย ย ย ย ย sessionResults.forEach(r => retrievedContext += `[Doc: ${r.source}]\n${r.text}\n`);
ย ย ย ย }

ย ย ย ย // Step F: Tightened AI Response
ย ย ย ย const systemPrompt = `
You are the B&E Solutions Navigator for Greensboro. 
Analyze the USER MESSAGE against the provided NC STATUTE CONTEXT.

CONTEXT FROM 57,407 NCGS CHUNKS:
${retrievedContext}

OPERATIONAL DIRECTIVES:
1. DEFINITION MODE: Provide a clear explanation first, then cite the relevant NCGS Chapter.
2. INDEPENDENT OBLIGATION RULE: Emphasize that rent and repairs are independent obligations in NC.
3. MANDATORY WARNING: Warn that ignoring legal notices leads to a "Default Judgment" (NCGS ยง 1A-1).
4. NO CONVERSATIONAL FILLER: Be a direct Navigator.

RETURN JSON: { "summary": "", "source": "NCGS Chapter ${detectedChapter || 'General'}", "deadline": "", "task": "", "urgency": "", "advice": "", "draft": "" }
`;

ย ย ย ย const completion = await openai.chat.completions.create({
ย ย ย ย ย ย model: "gpt-4o-mini",
ย ย ย ย ย ย messages: [{ role: "system", content: systemPrompt }, { role: "user", content: hybridQuery }],
ย ย ย ย ย ย response_format: { "type": "json_object" }
ย ย ย ย });

ย ย ย ย res.json({ reply: JSON.parse(completion.choices[0].message.content) });

ย ย } catch (error) {
ย ย ย ย console.error("Critical Error:", error);
ย ย ย ย res.status(500).json({ error: "The Navigator is currently offline." });
ย ย }
});

// --- 5. START SERVER ---
const PORT = process.env.PORT || 3001; 
app.listen(PORT, () => console.log(`๐ก๏ธ Navigator active on port ${PORT}`)); lets see the new server
